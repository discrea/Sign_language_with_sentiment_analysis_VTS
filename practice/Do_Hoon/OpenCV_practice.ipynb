{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d32545",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fv/ycxq950n3_s5t1xm7d6yy2tw0000gp/T/ipykernel_88401/2497722310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b921036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "        image = cv2.flip(cv2.imread(file), 1)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print handedness and draw hand landmarks on the image.\n",
    "        print('Handedness:', results.multi_handedness)\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            print('hand_landmarks:', hand_landmarks)\n",
    "            print(\n",
    "                f'Index finger tip coordinates: (',\n",
    "                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "            )\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        cv2.imwrite(\n",
    "            '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks: \n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fc38f",
   "metadata": {},
   "source": [
    "# Python OpenCV 강좌 : 제 2강 - 카메라 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fdff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while cv2.waitKey(33) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1674419",
   "metadata": {},
   "source": [
    "# Python OpenCV 강좌 : 제 3강 - 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e4a5893",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-vi271kac\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-30ee78a0eb28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image/Star.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_ANYCOLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"plane\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-vi271kac\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"img/plane.jpg\", cv2.IMREAD_ANYCOLOR)\n",
    "cv2.imshow(\"plane\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e2e9c84",
   "metadata": {},
   "source": [
    "image = cv2.imread(fileName, flags)는 파일 경로(fileName)의 이미지 파일을 플래그(flags) 설정에 따라 불러옵니다.\n",
    "\n",
    "파일 경로(fileName)는 상대 경로 또는 절대 경로를 사용하여 이미지를 불러옵니다.\n",
    "\n",
    "flags은 이미지를 초기에 불러올 때 적용할 초기 상태를 의미합니다.\n",
    "\n",
    "flags\n",
    "cv2.IMREAD_UNCHANGED : 원본 사용\n",
    "cv2.IMREAD_GRAYSCALE : 1 채널, 그레이스케일 적용\n",
    "cv2.IMREAD_COLOR : 3 채널, BGR 이미지 사용\n",
    "cv2.IMREAD_ANYDEPTH : 이미지에 따라 정밀도를 16/32비트 또는 8비트로 사용\n",
    "cv2.IMREAD_ANYCOLOR : 가능한 3 채널, 색상 이미지로 사용\n",
    "cv2.IMREAD_REDUCED_GRAYSCALE_2 : 1 채널, 1/2 크기, 그레이스케일 적용\n",
    "cv2.IMREAD_REDUCED_GRAYSCALE_4 : 1 채널, 1/4 크기, 그레이스케일 적용\n",
    "cv2.IMREAD_REDUCED_GRAYSCALE_8 : 1 채널, 1/8 크기, 그레이스케일 적용\n",
    "cv2.IMREAD_REDUCED_COLOR_2 : 3 채널, 1/2 크기, BGR 이미지 사용\n",
    "cv2.IMREAD_REDUCED_COLOR_4 : 3 채널, 1/4 크기, BGR 이미지 사용\n",
    "cv2.IMREAD_REDUCED_COLOR_8 : 3 채널, 1/8 크기, BGR 이미지 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c683a9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 256 3\n"
     ]
    }
   ],
   "source": [
    "height, width, channel = image.shape\n",
    "print(height, width , channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a6e6c",
   "metadata": {},
   "source": [
    "# Python OpenCV 강좌 : 제 4강 - 비디오 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27d45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_frame(capture):\n",
    "    i = 0\n",
    "    print(i)\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    while capture is None:\n",
    "        print(i)\n",
    "        i += 1\n",
    "        capture.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38c43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(\"Image/Star.mp4\")\n",
    "\n",
    "while cv2.waitKey(33) < 0:\n",
    "    if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de2ecf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-44ad09cf7dc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(\"/Image/test.mp4\")\n",
    "i=0\n",
    "\n",
    "try:\n",
    "    while cv2.waitKey(33) < 0:\n",
    "        if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            i = 0\n",
    "\n",
    "        ret, frame = capture.read()\n",
    "        if frame is not None:\n",
    "            cv2.imshow(\"VideoFrame\", frame)\n",
    "        else:\n",
    "            capture.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            i += 1\n",
    "#         cv2.imshow(\"VideoFrame\", frame)\n",
    "        \n",
    "finally:\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e9e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a383a",
   "metadata": {},
   "source": [
    "# Python OpenCV 강좌 : 제 5강 - 대칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4efe1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/glass.jpg\", cv2.IMREAD_COLOR)\n",
    "dst = cv2.flip(src, -1)\n",
    "# dst = cv2.flip(src, flipCode)\n",
    "# flipCode < 0은 XY 축 대칭(상하좌우 대칭)을 적용합니다.\n",
    "# flipCode = 0은 X 축 대칭(상하 대칭)을 적용합니다.\n",
    "# flipCode > 0은 Y 축 대칭(좌우 대칭)을 적용합니다.\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e65114",
   "metadata": {},
   "source": [
    "# Python OpenCV 강좌 : 제 6강 - 회전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bcecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/ara.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "height, width, channel = src.shape\n",
    "matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)\n",
    "# matrix = cv2.getRotationMatrix2D(center, angle, scale)는 \n",
    "# 중심점(center), 각도(angle), 비율(scale)로 매핑 변환 행렬(matrix)을 생성합니다.\n",
    "dst = cv2.warpAffine(src, matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8d7ab",
   "metadata": {},
   "source": [
    "# Python OpenCV 강좌 : 제 7강 - 확대 & 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/fruits.jpg\", cv2.IMREAD_COLOR)\n",
    "height, width, channel = src.shape\n",
    "\n",
    "dst = cv2.pyrUp(src, dstsize=(width * 2, height * 2), borderType=cv2.BORDER_DEFAULT)\n",
    "dst2 = cv2.pyrDown(src)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9d557",
   "metadata": {},
   "source": [
    "# 제 8강 - 크기 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "461059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/champagne.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "dst = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "dst2 = cv2.resize(src, dsize=(0, 0), fx=0.3, fy=0.7, interpolation=cv2.INTER_LINEAR)\n",
    "# dst = cv2.resize(src, dstSize, fx, fy, interpolation)는 \n",
    "# 입력 이미지(src), 절대 크기(dstSize), 상대 크기(fx, fy), 보간법(interpolation)으로 \n",
    "# 출력 이미지(dst)을 생성합니다.\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cea719",
   "metadata": {},
   "source": [
    "# 제 9강 - 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bfd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./Image/chess.jpg\", cv2.IMREAD_COLOR)\n",
    "dst = src[100:600, 200:700].copy()\n",
    "# OpenCV의 이미지는 이미지는 numpy 배열 형식과 동일합니다.\n",
    "# src 이미지에 src[높이(행), 너비(열)]로 관심 영역을 설정합니다.\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b0100",
   "metadata": {},
   "source": [
    "# 제 10강 - 색상 공간 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd773fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/crow.jpg\", cv2.IMREAD_COLOR)\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a0b00",
   "metadata": {},
   "source": [
    "# 제 11강 - 역상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97b0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/whitebutterfly.jpg\", cv2.IMREAD_COLOR)\n",
    "dst = cv2.bitwise_not(src)\n",
    "# 153은 0b10011001의 값을 가지며, \n",
    "# 102는 0b01100110의 값을 갖습니다.\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554de6e",
   "metadata": {},
   "source": [
    "# 제 12강 - 이진화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd632ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/geese.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret100, dst100 = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "ret200, dst200 = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY) # 더 어두워짐\n",
    "\n",
    "# retval, dst = cv2.threshold(src, thresh, maxval, type)는 \n",
    "# 입력 이미지(src)를 임곗값 형식(type)에 따라 임곗값(thresh)과 최댓값(maxval)을 활용하여 \n",
    "# 설정 임곗값(retval)과 결과 이미지(dst)를 반환합니다.\n",
    "cv2.imshow(\"dst100\", dst100)\n",
    "cv2.imshow(\"dst200\", dst200)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75a0e265",
   "metadata": {},
   "source": [
    "임계값 형식\n",
    "=========================================================\n",
    "cv2.THRESH_BINARY\t\n",
    "---------------------------------------------------------\n",
    "dst = (src > thresh) ? maxval : 0\n",
    "(임곗값을 초과할 경우 maxval, 아닐 경우 0)\n",
    "=========================================================\n",
    "cv2.THRESH_BINARY_INV\t\n",
    "---------------------------------------------------------\n",
    "dst = (src > thresh) ? 0 : maxval\n",
    "(임곗값을 초과할 경우 0, 아닐 경우 maxval)\n",
    "=========================================================\n",
    "cv2.THRESH_TRUNC\t\n",
    "---------------------------------------------------------\n",
    "dst = (src > thresh) ? thresh : src\n",
    "(임곗값을 초과할 경우 thresh, 아닐 경우 변형 없음)\n",
    "=========================================================\n",
    "cv2.THRESH_TOZERO\t\n",
    "---------------------------------------------------------\n",
    "dst = (src > thresh) ? src : 0\n",
    "(임곗값을 초과할 경우 변형 없음, 아닐 경우 0)\n",
    "=========================================================\n",
    "cv2.THRESH_TOZERO_INV\t\n",
    "---------------------------------------------------------\n",
    "dst = (src > thresh) ? 0 : src\n",
    "(임곗값을 초과할 경우 0, 아닐 경우 변형 없음)\n",
    "=========================================================\n",
    "cv2.THRESH_MASK\t\n",
    "---------------------------------------------------------\n",
    "검은색 이미지로 변경(마스크용)\n",
    "=========================================================\n",
    "cv2.THRESH_OTSU\t\n",
    "---------------------------------------------------------\n",
    "오츠 알고리즘 적용(단일 채널 이미지에만 적용 가능)\n",
    "=========================================================\n",
    "cv2.THRESH_TRIANGLE\t\n",
    "---------------------------------------------------------\n",
    "삼각형(Triangle) 알고리즘 적용(단일 채널 이미지에만 적용 가능)\n",
    "========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddce2a8",
   "metadata": {},
   "source": [
    "# 제 13강 - 흐림 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cecd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/plumb.jpg\", cv2.IMREAD_COLOR)\n",
    "src = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "dst = cv2.blur(src, (9, 9), anchor=(-1, -1), borderType=cv2.BORDER_DEFAULT)\n",
    "# dst = cv2.blur(src, ksize, anchor, borderType)는 \n",
    "# 입력 이미지(src)를 커널 크기(ksize), 고정점(anchor), 테두리 외삽법(borderType)으로 \n",
    "# 흐림 효과를 적용한 결과 이미지(dst)를 반환합니다.\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac053cb9",
   "metadata": {},
   "source": [
    "# 제 14강 - 가장자리 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a73d7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/wheat.jpg\", cv2.IMREAD_COLOR)\n",
    "src = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, 3)          \n",
    "# 인접한 픽셀들의 차이로 기울기(Gradient)의 크기를 구합니다.\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)  \n",
    "# 2차 미분의 형태로 가장자리가 밝은 부분에서 발생한 것인지, 어두운 부분에서 발생한 것인지 알 수 있습니다.\n",
    "canny = cv2.Canny(src, 100, 255)                     \n",
    "# laplacian 필터 방식을 개선한 방식으로 x와 y에 대해 1차 미분을 계산한 다음, 네 방향으로 미분합니다.\n",
    "\n",
    "cv2.imshow(\"sobel\", sobel)\n",
    "cv2.imshow(\"laplacian\", laplacian)\n",
    "cv2.imshow(\"canny\", canny)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f37a8",
   "metadata": {},
   "source": [
    "# 제 15강 - HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "094bc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/tomato.jpg\", cv2.IMREAD_COLOR)\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "cv2.imshow(\"hsv\", hsv)\n",
    "cv2.imshow(\"h\", h) # 색상(Hue)은 빨간색, 노란색, 파란색 등으로 인식되는 색상 중 하나 또는 둘의 조합과 유사한 것처럼 보이는 시각적 감각의 속성을 의미합니다.\n",
    "cv2.imshow(\"s\", s) # 채도(Saturation)는 이미지의 색상 깊이로, 색상이 얼마나 선명한(순수한) 색인지를 의미합니다.\n",
    "cv2.imshow(\"v\", v) # 명도(Value)는 색의 밝고 어두운 정도를 의미합니다. 명도가 높을수록 색상이 밝아지며, 명도가 낮을수록 색상이 어두워집니다.\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abbebe",
   "metadata": {},
   "source": [
    "# 제 16강 - 배열 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a236ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/tomato.jpg\", cv2.IMREAD_COLOR)\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "lower_red = cv2.inRange(hsv, (0, 100, 100), (5, 255, 255))\n",
    "upper_red = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255))\n",
    "added_red = cv2.addWeighted(lower_red, 1.0, upper_red, 1.0, 0.0)\n",
    "\n",
    "red = cv2.bitwise_and(hsv, hsv, mask = added_red)\n",
    "red = cv2.cvtColor(red, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"lower_red\", lower_red)\n",
    "cv2.imshow(\"upper_red\", upper_red)\n",
    "cv2.imshow(\"red\", red)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a8507",
   "metadata": {},
   "source": [
    "# 제 17강 - 채널 분리 & 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "138aa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/sausage.jpg\", cv2.IMREAD_COLOR)\n",
    "src = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "b, g, r = cv2.split(src)\n",
    "inverse = cv2.merge((r, g, b))\n",
    "\n",
    "cv2.imshow(\"b\", b)\n",
    "cv2.imshow(\"g\", g)\n",
    "cv2.imshow(\"r\", r)\n",
    "cv2.imshow(\"inverse\", inverse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36124b97",
   "metadata": {},
   "source": [
    "# 제 18강 - 도형 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a1efb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = np.zeros((768, 1366, 3), dtype=np.uint8)\n",
    "\n",
    "src = cv2.line(src, (100, 100), (1200, 100), (0, 0, 255), 3, cv2.LINE_AA)\n",
    "src = cv2.circle(src, (300, 300), 50, (0, 255, 0), cv2.FILLED, cv2.LINE_4)\n",
    "src = cv2.rectangle(src, (500, 200), (1000, 400), (255, 0, 0), 5, cv2.LINE_8)\n",
    "src = cv2.ellipse(src, (1200, 300), (100, 50), 0, 90, 180, (255, 255, 0), 2)\n",
    "\n",
    "pts1 = np.array([[100, 500], [300, 500], [200, 600]])\n",
    "pts2 = np.array([[600, 500], [800, 500], [700, 600]])\n",
    "src = cv2.polylines(src, [pts1], True, (0, 255, 255), 2)\n",
    "src = cv2.fillPoly(src, [pts2], (255, 0, 255), cv2.LINE_AA)\n",
    "\n",
    "src = cv2.putText(src, \"YUNDAEHEE\", (900, 600), cv2.FONT_HERSHEY_COMPLEX, 2, (255, 255, 255), 3)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1998a176",
   "metadata": {},
   "source": [
    "# 제 19강 - 기하학적 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afe0a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/harvest.jpg\", cv2.IMREAD_COLOR)\n",
    "height, width, channel = src.shape\n",
    "\n",
    "srcPoint = np.array([[300, 200], [400, 200], [500, 500], [200, 500]], dtype=np.float32)\n",
    "dstPoint = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(srcPoint, dstPoint)\n",
    "dst = cv2.warpPerspective(src, matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310ac91",
   "metadata": {},
   "source": [
    "# 제 20강 - 캡쳐 및 녹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ddf3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹화 시작\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-50efd0783815>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"녹화 시작\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./result\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".avi\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfourcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"녹화 중지\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(\"/Image/Star.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "record = False\n",
    "\n",
    "while True:\n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open(\"/Image/Star.mp4\")\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "    if frame is not None:\n",
    "        cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "    key = cv2.waitKey(33)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == 26:\n",
    "        print(\"캡쳐\")\n",
    "        cv2.imwrite(\"./result\" + str(now) + \".png\", frame)\n",
    "    elif key == 24:\n",
    "        print(\"녹화 시작\")\n",
    "        record = True\n",
    "        video = cv2.VideoWriter(\"./result\" + str(now) + \".avi\", fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
    "    elif key == 3:\n",
    "        print(\"녹화 중지\")\n",
    "        record = False\n",
    "        video.release()\n",
    "        \n",
    "    if record == True:\n",
    "        print(\"녹화 중..\")\n",
    "        video.write(frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71110320",
   "metadata": {},
   "source": [
    "# 제 21강 - 윤곽선 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4692e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2 -1  1 -1]\n",
      "1 [-1 -1 -1  0]\n",
      "2 [ 4  0  3 -1]\n",
      "3 [-1 -1 -1  2]\n",
      "4 [ 6  2  5 -1]\n",
      "5 [-1 -1 -1  4]\n",
      "6 [ 8  4  7 -1]\n",
      "7 [-1 -1 -1  6]\n",
      "8 [ 9  6 -1 -1]\n",
      "9 [10  8 -1 -1]\n",
      "10 [11  9 -1 -1]\n",
      "11 [-1 10 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread(\"Image/contours.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
    "ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "binary = cv2.bitwise_not(binary)\n",
    "# 윤곽선(컨투어)를 검출하는 주된 요소는 하얀색의 객체를 검출합니다.\n",
    "# 그러므로 배경은 검은색이며 검출하려는 물체는 하얀색의 성질을 띄게끔 변형합니다.\n",
    "# 이진화 처리 후, 반전시켜 검출하려는 물체를 하얀색의 성질을 띄도록 변환합니다.\n",
    "\n",
    "contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    cv2.drawContours(src, [contours[i]], 0, (0, 0, 255), 2)\n",
    "    cv2.putText(src, str(i), tuple(contours[i][0][0]), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1)\n",
    "    print(i, hierarchy[0][i])\n",
    "    cv2.imshow(\"src\", src)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb3383",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704d9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7ee1a6b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b4c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c04de395",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034b82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a9777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
